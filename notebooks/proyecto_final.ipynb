{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b36761ab-27e0-436e-9364-d5d78c9de6aa",
   "metadata": {},
   "source": [
    "# Aqui inicia mi sufrimiento :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0734abf6-fdf5-41bb-897d-7e830b7a703f",
   "metadata": {},
   "source": [
    "# PROYECTO FINAL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f105ba-bc9e-4ecc-8cc6-31f48eb3973d",
   "metadata": {},
   "source": [
    "## Sistemas Distribuidos con PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6529ba-82b3-4d45-ad34-217567980814",
   "metadata": {},
   "source": [
    "Este proyecto implementa lo que se ha visto en clases en una serie de ejercicios a las cuales llamo un **sistema de recomendaci√≥n de libros** utilizando:\n",
    "- **100 libros** m√°s descargados de Project Gutenberg (Omitiendo 2 ya que estos denegaban el acceso...)\n",
    "- **PySpark** para procesamiento distribuido\n",
    "- **TF-IDF** para an√°lisis de texto\n",
    "- **Similitud coseno** para encontrar libros similares\n",
    "- Y las ense√±anzas del profe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81ab2e8-c827-4e56-8630-6e32b7433b30",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CELDA 1: Configuraci√≥n de Rutas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1dc7cd-9fd2-4c4b-ad2f-5d65dcde75cd",
   "metadata": {},
   "source": [
    "**¬øQu√© hace?**\n",
    "Configura las rutas del proyecto para que Python pueda encontrar nuestros archivos de utilidades (`src/utils.py`).\n",
    "\n",
    "**Explicaci√≥n t√©cnica:**\n",
    "- `sys.path.append()` a√±ade directorios donde Python buscar√° m√≥dulos <details> <summary> ¬øPor que? </summary> (Antes tuvimos problemas con que el programa que no encontraba la ruta de SRC)</details>\n",
    "\n",
    "\n",
    "- `..` = directorio padre (ra√≠z del proyecto)\n",
    "- `../src` = carpeta de c√≥digo fuente<details>\n",
    "    <summary> ¬øQue hay ahi? </summary> \n",
    "    Ahi adentro se encuentran los archivos python donde uno descarga los libros (download_books.py) y otro donde se encarga de limpiar estos mismos como quitar los headers o footers para que no extorben en el analisis (utils.py)\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "433a5e47-9932-438f-a8bf-4394212638ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rutas configuradas:\n",
      "  - /home/arturoallen/proyecto_52_sistemas/lib/python3.12/site-packages\n",
      "  - /home/arturoallen/Descargas/proyecto_sistemas-main\n",
      "  - /home/arturoallen/Descargas/proyecto_sistemas-main/src\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Agregar rutas del proyecto\n",
    "sys.path.append(os.path.abspath(\"..\"))  # ra√≠z del proyecto\n",
    "sys.path.append(os.path.abspath(\"../src\"))  # carpeta src\n",
    "\n",
    "# Verificar rutas\n",
    "print(\"Rutas configuradas:\")\n",
    "for path in sys.path[-3:]:\n",
    "    print(f\"  - {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b6cbe4-d551-414c-b1cd-d83fe5084d05",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CELDA 2: Descargar Recursos de NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78bc74a-185b-458b-bae2-0cec356ead26",
   "metadata": {},
   "source": [
    "**¬øQu√© hace?**\n",
    "Descarga las herramientas necesarias de NLTK para procesar texto en ingl√©s.\n",
    "\n",
    "**Lo que descarga:**\n",
    "- `punkt` y `punkt_tab` ‚Üí Separa texto en palabras (tokenizaci√≥n)<details><summary>En otras palabras</summary>Esto divide un texto grande en piezas m√°s peque√±as llamadas tokens.</details>\n",
    "\n",
    "- `stopwords` ‚Üí Lista de palabras comunes que no aportan significado (\"the\", \"a\", \"is\") <details>\n",
    "  <summary> ¬øDe donde sacamos esta herramienta? </summary>\n",
    "  Esta herramienta o mas bien libreria fue recomendada por el profesor para facilitarnos la detecci√≤n de stopwords\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70bf0cce-277a-4c2d-9279-eda87ff104ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando recursos de NLTK...\n",
      "‚úì NLTK configurado\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "print(\"Descargando recursos de NLTK...\")\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "print(\"‚úì NLTK configurado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e9da3f-8de6-4cd3-a39d-0c26d6526d31",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CELDA 3: Inicializar Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5ae35a-8dd2-4c83-b2b9-6ad323492441",
   "metadata": {},
   "source": [
    "**¬øQu√© hace?**\n",
    "Arranca el motor de Spark que procesar√° nuestros datos de forma distribuida.\n",
    "\n",
    "**Configuraci√≥n:**\n",
    "- `driver.memory: 6g` ‚Üí Memoria del coordinador (6 GB)<details><summary>Mas detalles</summary>Memoria para el driver.\n",
    "    - Este driver.memory recibe las instrucciones, reparte el trabajo y al final recoge los resultados.\n",
    "    - Los 6 GB significa que la m√°quina virtual va a reservar 6 GB solo para este coordinador.\n",
    "    - Esto procesara los 100 libros\n",
    "</details>\n",
    "\n",
    "- `executor.memory: 4g` ‚Üí Memoria de los trabajadores (4 GB)\n",
    "- `local[*]` ‚Üí Usa todos los cores de tu CPU\n",
    "\n",
    "\\\n",
    "**¬øPor qu√© Spark?**\n",
    "- Para procesar 100 libros (~75 MB) de forma eficiente y paralela.<details>\n",
    "    <summary> Y... </summary> \n",
    "    ...porque el profe nos lo pidio\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35c8eca0-8361-4af2-bd81-0e7727d96a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/08 22:40:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/12/08 22:40:09 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Spark inicializado\n",
      "  Version: 4.0.1\n",
      "  Master: local[*]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ProyectoFinal_RecomendacionLibros\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"6g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Reducir logs\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(\"‚úì Spark inicializado\")\n",
    "print(f\"  Version: {spark.version}\")\n",
    "print(f\"  Master: {spark.sparkContext.master}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b85d2313-1fcb-4619-9227-8a5f50c345c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CELDA 4: Importar Funciones de Utilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a69880f-56d6-48b3-ac38-117eeadca922",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**¬øQu√© hace?**\\\n",
    "Carga las funciones que creamos para procesar los libros desde la carpeta src al archivo utils.py\n",
    "\n",
    "**Funciones importadas:**\n",
    "- `read_txt()` ‚Üí Lee un archivo .txt sin importar el tipo de encoding, evitando errores por acentos o caracteres raros.\n",
    "- `strip_gutenberg_headers()` ‚Üí Quita las licencias, advertencias y texto extra que agregan los libros.\n",
    "- `preprocess_text()` ‚Üí Limpia el texto aplicando estos filtros:\n",
    "    - min√∫sculas\n",
    "    - tokenizar\n",
    "    - quitar stopwords\n",
    "    - quitar puntuaci√≥n<br>\n",
    "- `load_all_books()` ‚Üí Busca todos los .txt de la carpeta y:\\\n",
    "  Es la funci√≥n que carga todos los libros del proyecto.\n",
    "    - los lee\n",
    "    - los limpia\n",
    "    - los convierte en una lista/diccionario de libros procesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b18b06b-0ec8-4475-9598-02b1bde9a6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Utilidades importadas\n"
     ]
    }
   ],
   "source": [
    "from src.utils import (\n",
    "    read_txt,\n",
    "    strip_gutenberg_headers,\n",
    "    preprocess_text,\n",
    "    load_all_books\n",
    ")\n",
    "\n",
    "print(\"‚úì Utilidades importadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da20a93-d253-4d3b-988d-65a24569b75e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CELDA 5 y 6: Cargar 100 Libros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc2af80-4949-415e-8b79-2ea4dd9db477",
   "metadata": {},
   "source": [
    "**¬øQu√© hace?**\n",
    "Lee los 100 lirbos .txt desde la carpeta `data/` y los preprocesa.\n",
    "\n",
    "**¬øEn que consiste el proceso?**\n",
    "1. Lee el archivo\n",
    "2. Elimina headers/footers\n",
    "3. Convierte a min√∫sculas\n",
    "4. Separa en palabras (tokens)\n",
    "5. Elimina stopwords (\"the\", \"a\", etc.)\n",
    "6. Elimina puntuaci√≥n y n√∫meros\n",
    "\n",
    "**Resultado:**\n",
    "Una lista con 100 libros, cada uno con:\n",
    "- ID del libro (usando los ID originales de la pagina)\n",
    "- Nombre del archivo\n",
    "- Texto completo\n",
    "- Lista de palabras limpias (tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b046493d-9de7-48ae-905f-d889e8f27cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desmarcar el comentario en caso de extrema emergencia (No tener los libros)\n",
    "# python3 src/download_books.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5548773-4fb8-4791-8945-456cf428e3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Cargando 7 libros desde ../data/\n",
      "‚úÖ Total de libros cargados exitosamente: 7\n",
      "\n",
      "\n",
      "üìä Resumen de carga:\n",
      "   Total de libros: 7\n",
      "   Ejemplo - ID: If the Eternity Should Fail, Tokens: 206\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data\"\n",
    "books = load_all_books(data_dir, max_books=100)\n",
    "\n",
    "print(f\"\\nüìä Resumen de carga:\")\n",
    "print(f\"   Total de libros: {len(books)}\")\n",
    "if books:\n",
    "    ejemplo = books[0]\n",
    "    print(f\"   Ejemplo - ID: {ejemplo[0]}, Tokens: {len(ejemplo[3])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e19a27-a5bf-4c65-8776-cb644ba39a9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CELDA 7: Crear DataFrame de Spark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a187e94-7db3-46c0-9c2f-01aa1fb5d8ff",
   "metadata": {},
   "source": [
    "**¬øQu√© hace?**\n",
    "Convierte nuestra lista de libros en un **DataFrame de Spark** (como una especie de tabla de Excel gigante).\n",
    "\n",
    "**Columnas del DataFrame:**\n",
    "- `book_id` ‚Üí ID √∫nico del libro (ej: \"84\", \"1342\")\n",
    "- `title` ‚Üí Nombre del archivo (ej: \"84.txt\")\n",
    "- `text` ‚Üí Texto completo del libro\n",
    "- `tokens` ‚Üí Lista de palabras procesadas\n",
    "\n",
    "**¬øPor qu√© un DataFrame?**\n",
    "Spark puede procesar DataFrames de forma paralela y distribuida.\n",
    "<details><summary>Comentario</summary> Creemos que no se ve las columnas de \"text\" y \"tokens\" porque estamos usando una maquina virutal para correr este codigo y la verdad a este punto en el que estoy hubiera preferido instalar linux pero en la laptop, casi no la uso</details>\n",
    "<br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03d1f561-be48-42d5-8a81-ece277d9b2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando DataFrame de Spark...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì DataFrame creado con 7 documentos\n",
      "\n",
      "+---------------------------+-------------------------------+\n",
      "|book_id                    |title                          |\n",
      "+---------------------------+-------------------------------+\n",
      "|If the Eternity Should Fail|If the Eternity Should Fail.txt|\n",
      "|Man On The Edge            |Man On The Edge.txt            |\n",
      "|Speed Of Light             |Speed Of Light.txt             |\n",
      "|The Great Unknown          |The Great Unknown.txt          |\n",
      "|The Red And The Black      |The Red And The Black.txt      |\n",
      "+---------------------------+-------------------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import ArrayType, StringType\n",
    "print(\"Creando DataFrame de Spark...\")\n",
    "df = spark.createDataFrame(\n",
    "    [(b[0], b[1], b[3]) for b in books],\n",
    "    schema=[\"book_id\", \"title\", \"tokens\"]\n",
    ")\n",
    "print(f\"‚úì DataFrame creado con {df.count()} documentos\\n\")\n",
    "df.select(\"book_id\", \"title\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7075463e-47af-47da-b461-7c92cfad75c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CELDA 8: Crear Vocabulario (CountVectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43c0a3d-f909-49de-bd0a-36601592ee25",
   "metadata": {},
   "source": [
    "**¬øQu√© hace?**\\\n",
    "Crea un **vocabulario** con las 2000 palabras m√°s importantes de todos los libros.\n",
    "\n",
    "**Proceso:**\n",
    "1. Cuenta cu√°ntas veces aparece cada palabra en cada libro\n",
    "2. Selecciona las 2000 palabras m√°s frecuentes\n",
    "3. Filtra palabras que aparecen en menos de 2 libros (muy raras)\n",
    "\n",
    "**Resultado:**\\\n",
    "Cada libro se representa como un vector de 2000 n√∫meros (frecuencias de palabras).\n",
    "<details>\n",
    "  <summary>Detalles del codigo</summary>\n",
    "  <p>Par√°metros:</p>\n",
    "  <ul>\n",
    "    <li>VOCAB_SIZE=2000: limita el vocabulario a las 2000 palabras m√°s frecuentes. Evita vectores enormes.</li>\n",
    "    <li>MIN_DF=2: elimina palabras que aparecen en menos de 2 documentos (filtra ruido / typos).</li>\n",
    "  </ul>\n",
    "</details>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3486077-f274-439a-a567-977f14d59f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando vocabulario con CountVectorizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Vocabulario creado\n",
      "  Tama√±o del vocabulario: 93 palabras\n",
      "  Top 10 palabras: ['falling', 'eternity', 'time', 'line', 'world', 'nothing', 'edge', 'waiting', 'us', 'ending']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "print(\"Creando vocabulario con CountVectorizer...\")\n",
    "\n",
    "VOCAB_SIZE = 2000\n",
    "MIN_DF = 2\n",
    "\n",
    "cv = CountVectorizer(\n",
    "    inputCol=\"tokens\",\n",
    "    outputCol=\"raw_features\",\n",
    "    vocabSize=VOCAB_SIZE,\n",
    "    minDF=MIN_DF\n",
    ")\n",
    "\n",
    "cv_model = cv.fit(df)\n",
    "df = cv_model.transform(df)\n",
    "df = df.drop(\"tokens\")  \n",
    "\n",
    "actual_vocab_size = len(cv_model.vocabulary)\n",
    "print(f\"‚úì Vocabulario creado\")\n",
    "print(f\"  Tama√±o del vocabulario: {actual_vocab_size} palabras\")\n",
    "print(f\"  Top 10 palabras: {cv_model.vocabulary[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d6e2eb-bce7-47e7-9456-a16c03c94e98",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CELDA 9: Calcular TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4a4951-3252-4492-99dd-a72887e6b499",
   "metadata": {},
   "source": [
    "**¬øQu√© hace?**\\\n",
    "Calcula **TF-IDF** (Term Frequency - Inverse Document Frequency) para cada palabra.\n",
    "\n",
    "**¬øQu√© es TF-IDF?**\\\n",
    "Un n√∫mero que indica el **peso** o **importancia** en una palabra para un libro espec√≠fico.\n",
    "\n",
    "**F√≥rmula simple:**\n",
    "- **TF** (frecuencia): ¬øCu√°ntas veces aparece en ESTE libro?\n",
    "- **IDF** (rareza): ¬øQu√© tan rara es en TODOS los libros?\n",
    "- **TF-IDF** = TF √ó IDF\n",
    "\n",
    "**Ejemplo:**\n",
    "- \"elizabeth\" aparece mucho en Frankenstein ‚Üí TF alto\n",
    "- \"elizabeth\" NO aparece en otros libros ‚Üí IDF alto\n",
    "- **TF-IDF de \"elizabeth\"** = ALTO (palabra caracter√≠stica)\n",
    "\n",
    "**¬øAl final que se obtiene de todo esto?:**\\\n",
    "Cada libro tiene un vector TF-IDF que representa su contenido √∫nico.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edf6ce95-2df1-4dd5-9d6e-6aabb0933be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculando TF-IDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:=======>                                                  (1 + 7) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì TF-IDF calculado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import IDF\n",
    "\n",
    "print(\"\\nCalculando TF-IDF...\")\n",
    "\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"tfidf\")\n",
    "idf_model = idf.fit(df)\n",
    "df = idf_model.transform(df)\n",
    "df = df.drop(\"raw_features\") \n",
    "\n",
    "print(\"‚úì TF-IDF calculado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27740ee8-562e-4785-94b5-1ff086403a3f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CELDA 10: Normalizar Vectores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47c83a3-e2eb-4d6e-8fa5-ee7a21dc322d",
   "metadata": {},
   "source": [
    "**¬øQu√© hace?**\\\n",
    "Normaliza los vectores TF-IDF para que todos tengan la misma \"longitud\" matem√°tica.<details> <summary>Ejemplo</summary> Es como comparar la composici√≥n de dos bebidas sin importar el tama√±o del vaso.</details>\n",
    "\n",
    "**¬øPor qu√© normalizar?**\n",
    "- Libros largos tienen n√∫meros m√°s grandes\n",
    "- Queremos comparar **proporcionalmente**, no por tama√±o\n",
    "- Despu√©s de normalizar, los valores est√°n entre 0 y 1\n",
    "\n",
    "\n",
    "**Resultado:**\\\n",
    "Vectores `tfidf_norm` con valores entre 0 y 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c7eb27d-3444-424a-b8ad-84529f3f522c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizando vectores TF-IDF...\n",
      "‚úì Vectores normalizados\n",
      "\n",
      "DataFrame final:\n",
      "+---------------------------+-------------------------------+------------------------------------------------------------+\n",
      "|                    book_id|                          title|                                                  tfidf_norm|\n",
      "+---------------------------+-------------------------------+------------------------------------------------------------+\n",
      "|If the Eternity Should Fail|If the Eternity Should Fail.txt|(93,[1,2,3,4,5,6,7,8,9,11,12,18,21,22,24,26,32,33,35,39,4...|\n",
      "|            Man On The Edge|            Man On The Edge.txt|(93,[0,5,6,7,14,15,18,23,28,34,42,43,45,47,49,53,54,56,57...|\n",
      "|             Speed Of Light|             Speed Of Light.txt|(93,[2,6,8,13,14,15,20,22,26,33,35,39,46,47,63,66,69,82,8...|\n",
      "|          The Great Unknown|          The Great Unknown.txt|(93,[0,2,4,7,8,9,10,12,16,17,19,21,27,28,30,36,37,38,39,4...|\n",
      "+---------------------------+-------------------------------+------------------------------------------------------------+\n",
      "only showing top 4 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Normalizer\n",
    "\n",
    "print(\"Normalizando vectores TF-IDF...\")\n",
    "\n",
    "normalizer = Normalizer(inputCol=\"tfidf\", outputCol=\"tfidf_norm\", p=2.0)\n",
    "df = normalizer.transform(df)\n",
    "df = df.drop(\"tfidf\")\n",
    "\n",
    "print(\"‚úì Vectores normalizados\")\n",
    "print(\"\\nDataFrame final:\")\n",
    "df.select(\"book_id\", \"title\", \"tfidf_norm\").show(4, truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3fb2fa-be44-44b0-85ce-4d5a4270fa31",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CELDA 11: Crear Matriz de Similitud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d714ca8-b9a4-46f0-a2b4-6f3553a5e239",
   "metadata": {},
   "source": [
    "**¬øQu√© hace?**\n",
    "Crea una **matriz 100√ó100** que compara cada libro con todos los dem√°s.\n",
    "\n",
    "**Proceso:**\n",
    "1. Convierte vectores de Spark a NumPy (arrays de Python)\n",
    "2. Calcula el **producto punto** entre todos los pares de libros\n",
    "3. El resultado es la **similitud coseno**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6f57e3b-1357-4a11-8d18-bb6e305964da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando matriz de similitud...\n",
      "  ‚Üí Convirtiendo vectores a numpy...\n",
      "  ‚Üí Calculando similitudes...\n",
      "‚úì Matriz de similitud creada: (7, 7)\n",
      "  Rango de similitudes: [0.0303, 1.0000]\n",
      "  üìä 7 libros indexados num√©ricamente\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Creando matriz de similitud...\")\n",
    "\n",
    "# Recolectar datos\n",
    "rows = df.select(\"book_id\", \"title\", \"tfidf_norm\").collect()\n",
    "\n",
    "# Preparar estructuras de datos\n",
    "book_ids = [r[\"book_id\"] for r in rows]\n",
    "id_to_title = {r[\"book_id\"]: r[\"title\"] for r in rows}\n",
    "\n",
    "# üÜï NUEVO: Crear √≠ndices num√©ricos\n",
    "numeric_id_to_original = {i+1: book_ids[i] for i in range(len(book_ids))}  # 1, 2, 3...\n",
    "original_to_numeric_id = {book_ids[i]: i+1 for i in range(len(book_ids))}\n",
    "\n",
    "# Convertir vectores a numpy\n",
    "print(\"  ‚Üí Convirtiendo vectores a numpy...\")\n",
    "vectors = np.array([r[\"tfidf_norm\"].toArray() for r in rows])\n",
    "\n",
    "# Calcular matriz de similitud\n",
    "print(\"  ‚Üí Calculando similitudes...\")\n",
    "sim_matrix = np.dot(vectors, vectors.T)\n",
    "\n",
    "# Crear mapeos (mantener los originales tambi√©n)\n",
    "index_to_id = {i: book_ids[i] for i in range(len(book_ids))}\n",
    "id_to_index = {book_ids[i]: i for i in range(len(book_ids))}\n",
    "\n",
    "print(f\"‚úì Matriz de similitud creada: {sim_matrix.shape}\")\n",
    "print(f\"  Rango de similitudes: [{sim_matrix.min():.4f}, {sim_matrix.max():.4f}]\")\n",
    "print(f\"  üìä {len(numeric_id_to_original)} libros indexados num√©ricamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098ec04e-f535-4033-a75d-7495a80c4d2b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##  CELDA 12: Recomendar libros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f5e8c0-0931-438c-be2f-b77e9689f014",
   "metadata": {},
   "source": [
    "\n",
    "**¬øQu√© hace?**\\\n",
    "Ingresamos un libro, seguido de ello se encuentra los N libros m√°s similares (Por default y para evitar que la memoria muera pusimos 5).\n",
    "\n",
    "**Pasos:**\n",
    "1. Busca el libro en la matriz de similitud\n",
    "2. Obtiene sus similitudes con todos los dem√°s libros\n",
    "3. Ordena de mayor a menor similitud\n",
    "4. Retorna los top N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "520d6174-1846-44ea-bc9e-1bb6126ce3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendar_libros(libro_id, N=5):\n",
    "    # Convertir a string para comparaci√≥n\n",
    "    libro_id_str = str(libro_id)\n",
    "    \n",
    "    # üÜï Intentar con ID num√©rico primero\n",
    "    if libro_id_str.isdigit():\n",
    "        num_id = int(libro_id_str)\n",
    "        if num_id in numeric_id_to_original:\n",
    "            libro_id_str = numeric_id_to_original[num_id]\n",
    "            print(f\"üìñ Usando ID num√©rico {num_id} ‚Üí {libro_id_str}\")\n",
    "    \n",
    "    # Validar que existe\n",
    "    if libro_id_str not in id_to_index:\n",
    "        raise ValueError(f\"‚ùå Libro '{libro_id}' no encontrado\")\n",
    "    \n",
    "    # Resto del c√≥digo igual...\n",
    "    idx = id_to_index[libro_id_str]\n",
    "    similarities = sim_matrix[idx]\n",
    "\n",
    "    pairs = [\n",
    "        (index_to_id[i], float(similarities[i]))\n",
    "        for i in range(len(similarities))\n",
    "        if i != idx\n",
    "    ]\n",
    "\n",
    "    pairs_sorted = sorted(pairs, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # üÜï Agregar ID num√©rico a los resultados\n",
    "    results = [\n",
    "        (original_to_numeric_id[bid], bid, id_to_title[bid], score)\n",
    "        for bid, score in pairs_sorted[:N]\n",
    "    ]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f35f962-315d-4ed9-bc54-c9fa0d4aa2e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CELDA 13: Funci√≥n Palabras Importantes (NORMALIZADA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db84348-ebf1-409e-92c2-61b49f4bb6d8",
   "metadata": {},
   "source": [
    "\n",
    "**¬øQu√© hace?**\\\n",
    "Encuentra las M palabras m√°s caracter√≠sticas de un libro.\n",
    "\n",
    "**Proceso:**\n",
    "1. Obtiene el vector TF-IDF normalizado del libro\n",
    "2. Ordena las palabras por su score TF-IDF\n",
    "3. Retorna las top M palabras\n",
    "\n",
    "**¬øPor qu√© usa `tfidf_norm`?**\n",
    "Los valores est√°n entre 0 y 1, m√°s f√°ciles de interpretar como porcentajes.\n",
    "\n",
    "**Entrada:**\n",
    "- `libro_id` = \"84\"\n",
    "- `M` = 5\n",
    "\n",
    "**Salida:**\n",
    "```\n",
    "elizabeth ‚Üí 0.64 (64% de importancia)\n",
    "feelings  ‚Üí 0.15 (15% de importancia)\n",
    "henry     ‚Üí 0.12 (12% de importancia)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72d6bdb0-6247-4656-9b0d-7288401bc221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Funci√≥n palabras_importantes() definida (versi√≥n normalizada)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "def palabras_importantes(documento_id, M=10):\n",
    "    \n",
    "    doc_id_str = str(documento_id)\n",
    "    \n",
    "    # üÜï Convertir ID num√©rico a original\n",
    "    if doc_id_str.isdigit():\n",
    "        num_id = int(doc_id_str)\n",
    "        if num_id in numeric_id_to_original:\n",
    "            doc_id_str = numeric_id_to_original[num_id]\n",
    "    \n",
    "    # Buscar documento\n",
    "    row = df.filter(col(\"book_id\") == doc_id_str).select(\"tfidf_norm\").collect()\n",
    "    \n",
    "    if not row:\n",
    "        raise ValueError(f\"‚ùå Documento '{documento_id}' no encontrado\")\n",
    "    \n",
    "    # Resto del c√≥digo igual...\n",
    "    tfidf_vector = row[0][\"tfidf_norm\"]\n",
    "    vocab = cv_model.vocabulary\n",
    "    \n",
    "    items = list(zip(tfidf_vector.indices, tfidf_vector.values))\n",
    "    items_sorted = sorted(items, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    top_words = [\n",
    "        (vocab[idx], float(val))\n",
    "        for idx, val in items_sorted[:M]\n",
    "    ]\n",
    "    \n",
    "    return top_words\n",
    "\n",
    "\n",
    "print(\"‚úì Funci√≥n palabras_importantes() definida (versi√≥n normalizada)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc81317-f2f4-4052-9fcc-ef094a0161ea",
   "metadata": {},
   "source": [
    "## INPUTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b421d4-c9c1-40d2-ae02-eeca25c28827",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### CELDA 14: Cat√°logo Completo\n",
    "Muestra los 100 libros disponibles con sus IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1862a86e-8d0d-4deb-9b78-d59e31c50bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìö CAT√ÅLOGO COMPLETO DE LIBROS\n",
      "================================================================================\n",
      "\n",
      "Total: 7 libros\n",
      "\n",
      "  1. [ID:  1] If the Eternity Should Fail.txt          (Original: If the Eternity Should Fail)\n",
      "  2. [ID:  2] Man On The Edge.txt                      (Original: Man On The Edge)\n",
      "  3. [ID:  3] Speed Of Light.txt                       (Original: Speed Of Light)\n",
      "  4. [ID:  4] The Great Unknown.txt                    (Original: The Great Unknown)\n",
      "  5. [ID:  5] The Red And The Black.txt                (Original: The Red And The Black)\n",
      "  6. [ID:  6] The book of souls.txt                    (Original: The book of souls)\n",
      "  7. [ID:  7] When The River Runs Deep.txt             (Original: When The River Runs Deep)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìö CAT√ÅLOGO COMPLETO DE LIBROS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal: {len(book_ids)} libros\\n\")\n",
    "\n",
    "for num_id, original_id in numeric_id_to_original.items():\n",
    "    print(f\"{num_id:3}. [ID: {num_id:2}] {id_to_title[original_id]:40} (Original: {original_id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cfea0c-626b-4ce0-8026-49461350b8b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### CELDA 15: Recomendador con INPUT\n",
    "El usuario ingresa:\n",
    "- ID del libro\n",
    "- Cu√°ntas recomendaciones quiere\n",
    "‚Üí Sistema devuelve libros similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8bbba0f-7667-4759-a63a-27ff1ecb314a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "üìñ Ingresa el ID del libro (n√∫mero o nombre):  2\n",
      "üî¢ ¬øCu√°ntas recomendaciones?:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìñ BUSCANDO LIBRO...\n",
      "================================================================================\n",
      "\n",
      "üìñ Usando ID num√©rico 2 ‚Üí Man On The Edge\n",
      "üéØ TOP 5 RECOMENDACIONES:\n",
      "\n",
      "1. [ID:  6] [0.1823] The book of souls.txt\n",
      "2. [ID:  4] [0.1001] The Great Unknown.txt\n",
      "3. [ID:  5] [0.0834] The Red And The Black.txt\n",
      "4. [ID:  7] [0.0627] When The River Runs Deep.txt\n",
      "5. [ID:  1] [0.0454] If the Eternity Should Fail.txt\n",
      "\n",
      "‚úÖ 5 recomendaciones generadas\n"
     ]
    }
   ],
   "source": [
    "libro_id = input(\"\\nüìñ Ingresa el ID del libro (n√∫mero o nombre): \").strip()\n",
    "n_recs = int(input(\"üî¢ ¬øCu√°ntas recomendaciones?: \") or \"5\")\n",
    "\n",
    "try:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üìñ BUSCANDO LIBRO...\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    recomendaciones = recomendar_libros(libro_id, N=n_recs)\n",
    "    \n",
    "    print(f\"üéØ TOP {n_recs} RECOMENDACIONES:\\n\")\n",
    "    for i, (num_id, orig_id, title, score) in enumerate(recomendaciones, 1):\n",
    "        print(f\"{i}. [ID: {num_id:2}] [{score:.4f}] {title}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ {n_recs} recomendaciones generadas\")\n",
    "except ValueError as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aa848f-df70-4182-be4e-bff94be19ae7",
   "metadata": {},
   "source": [
    "### CELDA 16: Palabras Caracter√≠sticas con INPUT\n",
    "El usuario ingresa:\n",
    "- ID del libro\n",
    "- Cu√°ntas palabras quiere\n",
    "‚Üí Sistema muestra palabras clave con barras visuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9585b093-7183-4cf2-a96e-cc4f29827c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "üìñ Ingresa el ID del libro (n√∫mero o nombre):  2\n",
      "üî¢ ¬øCu√°ntas palabras?:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìñ Usando ID num√©rico 2 ‚Üí Man On The Edge\n",
      "\n",
      "================================================================================\n",
      "üìñ LIBRO: Man On The Edge.txt\n",
      "================================================================================\n",
      "\n",
      " 1. falling              ‚îÇ    0.93 ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      " 2. step                 ‚îÇ    0.11 ‚îÇ ‚ñà‚ñà‚ñà\n",
      " 3. wild                 ‚îÇ    0.11 ‚îÇ ‚ñà‚ñà‚ñà\n",
      " 4. around               ‚îÇ    0.11 ‚îÇ ‚ñà‚ñà‚ñà\n",
      " 5. head                 ‚îÇ    0.11 ‚îÇ ‚ñà‚ñà‚ñà\n",
      "\n",
      "‚úÖ Top 5 palabras generadas\n"
     ]
    }
   ],
   "source": [
    "# CELDA 19: Palabras Caracter√≠sticas con INPUT (CORREGIDA)\n",
    "\n",
    "libro_id = input(\"\\nüìñ Ingresa el ID del libro (n√∫mero o nombre): \").strip()\n",
    "m_palabras = int(input(\"üî¢ ¬øCu√°ntas palabras?: \") or \"10\")\n",
    "\n",
    "try:\n",
    "    # Convertir ID num√©rico si es necesario\n",
    "    libro_id_str = str(libro_id)\n",
    "    if libro_id_str.isdigit():\n",
    "        num_id = int(libro_id_str)\n",
    "        if num_id in numeric_id_to_original:\n",
    "            libro_id_str = numeric_id_to_original[num_id]\n",
    "            print(f\"üìñ Usando ID num√©rico {num_id} ‚Üí {libro_id_str}\")\n",
    "    else:\n",
    "        libro_id_str = libro_id\n",
    "    \n",
    "    # Validar que existe\n",
    "    if libro_id_str not in id_to_title:\n",
    "        print(f\"‚ùå Libro '{libro_id}' no encontrado\")\n",
    "    else:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"üìñ LIBRO: {id_to_title[libro_id_str]}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        palabras = palabras_importantes(libro_id_str, M=m_palabras)\n",
    "        \n",
    "        for i, (palabra, score) in enumerate(palabras, 1):\n",
    "            # Barra visual\n",
    "            bar = \"‚ñà\" * int((score / palabras[0][1]) * 30)\n",
    "            print(f\"{i:2}. {palabra:20} ‚îÇ {score:7.2f} ‚îÇ {bar}\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ Top {m_palabras} palabras generadas\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3438b9b6-fa34-4309-842a-d8a855c7a29e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
