{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d0aeaea-a76d-407d-b47d-f9397a84ca91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/usr/lib/python312.zip',\n",
       " '/tmp/spark-2fb1be88-37be-4dda-af47-6eda09c0d598/userFiles-e8dc0662-4335-4230-8223-60db99a3d4bd',\n",
       " '/usr/lib/python3.12',\n",
       " '/usr/lib/python3.12/lib-dynload',\n",
       " '',\n",
       " '/home/arturo/venv/lib/python3.12/site-packages',\n",
       " '/home/arturo/project_gutenberg',\n",
       " '/home/arturo/project_gutenberg/notebooks',\n",
       " '/home/arturo/project_gutenberg',\n",
       " '/home/arturo/project_gutenberg/notebooks']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Agregar la ruta del proyecto a sys.path\n",
    "sys.path.append(os.path.abspath(\"..\"))       # si el notebook estÃ¡ dentro de /notebooks\n",
    "sys.path.append(os.path.abspath(\".\"))        # si el notebook estÃ¡ en la raÃ­z\n",
    "\n",
    "# Mostrar rutas para confirmar\n",
    "sys.path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3da050cf-f697-435f-b5a9-f6357882eae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/arturo/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/arturo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/arturo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9e9024c-198a-459d-a771-b1c45a6924a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/12/05 22:26:10 WARN Utils: Your hostname, arturo-VirtualBox, resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "25/12/05 22:26:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/05 22:26:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/12/05 22:26:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ProyectoLibros</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7b4e81f190a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import ArrayType, StringType, IntegerType\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, IDF, Normalizer\n",
    "import numpy as np\n",
    "import os, json, pickle\n",
    "from src.utils import strip_gutenberg_headers, preprocess_text, read_txt, load_all_books\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ProyectoLibros\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\",\"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "059198e6-3d7b-439d-9b7a-a4cd0eeabd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"../data\"  # ajusta la ruta si es necesario\n",
    "books = []\n",
    "for fname in sorted(os.listdir(data_dir)):\n",
    "    if not fname.endswith(\".txt\"):\n",
    "        continue\n",
    "    book_id = os.path.splitext(fname)[0]\n",
    "    path = os.path.join(data_dir, fname)\n",
    "    raw = read_txt(path)\n",
    "    main = strip_gutenberg_headers(raw)\n",
    "    # NOTA: aquÃ­ guardamos texto completo y tokens para Spark\n",
    "    tokens = preprocess_text(main, language='english')\n",
    "    books.append((int(book_id) if book_id.isdigit() else book_id, fname, main, tokens))\n",
    "\n",
    "len(books)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff2ef864-264d-4366-abfe-3c72e6bd35cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/05 22:43:55 WARN TaskSetManager: Stage 1 contains a task of very large size (10072 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|book_id|   title|                                                        text|                                                      tokens|\n",
      "+-------+--------+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|     11|  11.txt|[Illustration]\\n\\n\\n\\n\\nAliceâ€™s Adventures in Wonderland\\...|[illustration, alice, adventures, wonderland, lewis, carr...|\n",
      "|   1342|1342.txt|[Illustration:\\n\\n                             GEORGE ALL...|[illustration, george, allen, publisher, 156, charing, cr...|\n",
      "|   1661|1661.txt|ï»¿The Project Gutenberg eBook of The Adventures of Sherloc...|[project, gutenberg, ebook, adventures, sherlock, holmes,...|\n",
      "|   2554|2554.txt|CRIME AND PUNISHMENT\\n\\nBy Fyodor Dostoevsky\\n\\n\\n\\nTrans...|[crime, punishment, fyodor, dostoevsky, translated, const...|\n",
      "+-------+--------+------------------------------------------------------------+------------------------------------------------------------+\n",
      "only showing top 4 rows\n"
     ]
    }
   ],
   "source": [
    "# Celda 3: DataFrame Spark con (book_id, title, text, tokens)\n",
    "df = spark.createDataFrame([(b[0], b[1], b[2], b[3]) for b in books],\n",
    "                           schema=[\"book_id\",\"title\",\"text\",\"tokens\"])\n",
    "df.show(4, truncate=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f51fa2b-0887-4023-9d44-e71b74ab5cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/05 22:44:56 WARN TaskSetManager: Stage 2 contains a task of very large size (10072 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------------------------------------------------------------+\n",
      "|book_id|   title|                                               tokens_nostop|\n",
      "+-------+--------+------------------------------------------------------------+\n",
      "|     11|  11.txt|[illustration, alice, adventures, wonderland, lewis, carr...|\n",
      "|   1342|1342.txt|[illustration, george, allen, publisher, 156, charing, cr...|\n",
      "|   1661|1661.txt|[project, gutenberg, ebook, adventures, sherlock, holmes,...|\n",
      "+-------+--------+------------------------------------------------------------+\n",
      "only showing top 3 rows\n"
     ]
    }
   ],
   "source": [
    "# Celda 5: StopWordsRemover\n",
    "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"tokens_nostop\")\n",
    "# si quieres usar tu propia lista: remover.setStopWords(my_list)\n",
    "df = remover.transform(df)\n",
    "df.select(\"book_id\",\"title\",\"tokens_nostop\").show(3, truncate=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71d6ed4e-0730-497f-b7ab-46386e06b504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/05 22:45:52 WARN TaskSetManager: Stage 3 contains a task of very large size (10072 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/12/05 22:46:02 WARN TaskSetManager: Stage 7 contains a task of very large size (10072 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/12/05 22:46:32 WARN TaskSetManager: Stage 8 contains a task of very large size (10072 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 8:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------------------------------------------------------------+\n",
      "|book_id|   title|                                                  tfidf_norm|\n",
      "+-------+--------+------------------------------------------------------------+\n",
      "|     11|  11.txt|(16730,[0,1,2,3,4,5,6,7,8,9,11,12,14,15,16,17,18,19,20,21...|\n",
      "|   1342|1342.txt|(16730,[0,1,2,3,4,5,6,7,8,9,10,11,12,14,15,16,17,18,19,20...|\n",
      "|   1661|1661.txt|(16730,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19...|\n",
      "+-------+--------+------------------------------------------------------------+\n",
      "only showing top 3 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Celda 6: CountVectorizer y IDF\n",
    "vocabSize = 20000\n",
    "cv = CountVectorizer(inputCol=\"tokens_nostop\", outputCol=\"raw_features\", vocabSize=vocabSize, minDF=2.0)\n",
    "cv_model = cv.fit(df)\n",
    "df = cv_model.transform(df)\n",
    "\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"tfidf\")\n",
    "idf_model = idf.fit(df)\n",
    "df = idf_model.transform(df)\n",
    "\n",
    "# Normalizar tfidf\n",
    "normalizer = Normalizer(inputCol=\"tfidf\", outputCol=\"tfidf_norm\", p=2.0)\n",
    "df = normalizer.transform(df)\n",
    "\n",
    "df.select(\"book_id\",\"title\",\"tfidf_norm\").show(3, truncate=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8639504d-67a8-4495-9a41-a65ec575580a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/05 22:51:25 WARN TaskSetManager: Stage 9 contains a task of very large size (10072 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 7: Convertir vectores de Spark a numpy en memoria\n",
    "rows = df.select(\"book_id\",\"title\",\"tfidf_norm\").collect()\n",
    "book_ids = []\n",
    "id_to_title = {}\n",
    "id_to_vec = {}\n",
    "for r in rows:\n",
    "    bid = r[\"book_id\"]\n",
    "    book_ids.append(bid)\n",
    "    id_to_title[bid] = r[\"title\"]\n",
    "    vec = np.array(r[\"tfidf_norm\"].toArray())\n",
    "    id_to_vec[bid] = vec\n",
    "\n",
    "len(book_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9da961e6-569a-4185-9438-a3299e1a04d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 8: Matriz de similitud (dot product porque vectores normalizados)\n",
    "n = len(book_ids)\n",
    "sim_matrix = np.zeros((n, n), dtype=float)\n",
    "for i in range(n):\n",
    "    vi = id_to_vec[book_ids[i]]\n",
    "    for j in range(i, n):\n",
    "        vj = id_to_vec[book_ids[j]]\n",
    "        s = float(np.dot(vi, vj))\n",
    "        sim_matrix[i, j] = s\n",
    "        sim_matrix[j, i] = s\n",
    "\n",
    "# guardar Ã­ndice -> book_id mapping\n",
    "index_to_id = {i: book_ids[i] for i in range(n)}\n",
    "id_to_index = {book_ids[i]: i for i in range(n)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26709430-88c1-49d0-8a7f-8aab303864db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libro base: 2600 2600.txt\n",
      "Recomendados:\n",
      "2554 2554.txt 0.2064\n",
      "1661 1661.txt 0.0938\n",
      "98 98.txt 0.0849\n",
      "84 84.txt 0.0671\n",
      "1342 1342.txt 0.0331\n"
     ]
    }
   ],
   "source": [
    "# Celda 9: recomendador\n",
    "def recomendar(libro_id, N=5):\n",
    "    if libro_id not in id_to_index:\n",
    "        raise ValueError(\"book_id no encontrado\")\n",
    "    idx = id_to_index[libro_id]\n",
    "    sims = sim_matrix[idx]\n",
    "    pairs = [(index_to_id[i], float(sims[i])) for i in range(len(sims)) if i != idx]\n",
    "    pairs_sorted = sorted(pairs, key=lambda x: x[1], reverse=True)\n",
    "    results = [(pid, id_to_title[pid], score) for pid, score in pairs_sorted[:N]]\n",
    "    return results\n",
    "\n",
    "# Ejemplo (reemplaza por un book_id real):\n",
    "ejemplo_id = book_ids[4]\n",
    "print(\"Libro base:\", ejemplo_id, id_to_title[ejemplo_id])\n",
    "print(\"Recomendados:\")\n",
    "for bid, title, score in recomendar(ejemplo_id, N=5):\n",
    "    print(bid, title, round(score, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2cf0be6-8161-4688-9b22-73a96aa4a740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/05 23:10:11 WARN TaskSetManager: Stage 15 contains a task of very large size (10072 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 15:=============================>                            (1 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('elizabeth', 508.5549974349543), ('jane', 392.38346120733877), ('mrs', 214.57207446389168), ('mr', 162.14192193341822), ('catherine', 133.53132034155934), ('illustration', 128.51854973937606), ('gardiner', 126.03044946063531)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Celda 10: top palabras por documento\n",
    "vocab = cv_model.vocabulary  # lista de tokens\n",
    "\n",
    "def top_palabras(libro_id, M=10):\n",
    "    # buscar fila en df con tfidf (no normalizada â€” usamos tfidf model output)\n",
    "    row = df.filter(col(\"book_id\") == libro_id).select(\"tfidf\").collect()\n",
    "    if not row:\n",
    "        raise ValueError(\"book_id no encontrado en DataFrame\")\n",
    "    vec = row[0][\"tfidf\"]  # SparseVector\n",
    "    items = list(zip(vec.indices, vec.values))\n",
    "    items_sorted = sorted(items, key=lambda x: x[1], reverse=True)\n",
    "    top = [(vocab[idx], float(val)) for idx, val in items_sorted[:M]]\n",
    "    return top\n",
    "\n",
    "# Ejemplo:\n",
    "print(top_palabras(ejemplo_id, M=7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d97b2cb7-cb3c-401d-8963-998842d48407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/05 23:13:52 WARN TaskSetManager: Stage 16 contains a task of very large size (10072 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/12/05 23:14:03 WARN TaskSetManager: Stage 17 contains a task of very large size (5477 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|book_id|title   |\n",
      "+-------+--------+\n",
      "|11     |11.txt  |\n",
      "|1342   |1342.txt|\n",
      "|1661   |1661.txt|\n",
      "|2554   |2554.txt|\n",
      "|2600   |2600.txt|\n",
      "|2701   |2701.txt|\n",
      "|3296   |3296.txt|\n",
      "|43     |43.txt  |\n",
      "|84     |84.txt  |\n",
      "|98     |98.txt  |\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"book_id\", \"title\").show(200, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c880b257-296f-4470-a19d-fafb76a84e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/05 23:14:30 WARN TaskSetManager: Stage 18 contains a task of very large size (10072 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/12/05 23:14:34 WARN TaskSetManager: Stage 19 contains a task of very large size (5477 KiB). The maximum recommended task size is 1000 KiB.\n",
      "IOPub data rate exceeded.                                                       \n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.title.contains(\"1342\")).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f890bd8-008c-42e2-b36b-dfea775288a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_palabras(libro_id, M=10):\n",
    "    row = df.filter(col(\"book_id\") == libro_id).select(\"tfidf\").collect()\n",
    "    if not row:\n",
    "        raise ValueError(\"book_id no encontrado\")\n",
    "    vec = row[0][\"tfidf\"]  # SparseVector\n",
    "    items = list(zip(vec.indices, vec.values))\n",
    "    items_sorted = sorted(items, key=lambda x: x[1], reverse=True)\n",
    "    vocab = cv_model.vocabulary\n",
    "    top = [(vocab[idx], float(val)) for idx, val in items_sorted[:M]]\n",
    "    return top\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b75182e3-bf46-49af-a604-e0b620dcc1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/05 23:23:57 WARN TaskSetManager: Stage 30 contains a task of very large size (10072 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('elizabeth', 72.53807715351286),\n",
       " ('geneva', 46.774187428689395),\n",
       " ('cottagers', 29.883508634996),\n",
       " ('lake', 27.31322461531896),\n",
       " ('cottage', 23.051241310895918),\n",
       " ('labours', 22.087810730214436),\n",
       " ('fiend', 21.214753124961042)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_palabras(84, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d124e2d5-341e-4c63-8537-99ebbf886bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸ“š DESCARGADOR DE PROJECT GUTENBERG\n",
      "============================================================\n",
      "\n",
      "Descargando 100 libros...\n",
      "Directorio: data/\n",
      "\n",
      "[1/100] Libro 1342:\n",
      "  âœ“ Descargado: 1342.txt\n",
      "[2/100] Libro 11:\n",
      "  âœ“ Descargado: 11.txt\n",
      "[3/100] Libro 84:\n",
      "  âœ“ Descargado: 84.txt\n",
      "[4/100] Libro 1661:\n",
      "  âœ“ Descargado: 1661.txt\n",
      "[5/100] Libro 2701:\n",
      "  âœ“ Descargado: 2701.txt\n",
      "[6/100] Libro 1952:\n",
      "  âœ“ Descargado: 1952.txt\n",
      "[7/100] Libro 174:\n",
      "  âœ“ Descargado: 174.txt\n",
      "[8/100] Libro 98:\n",
      "  âœ“ Descargado: 98.txt\n",
      "[9/100] Libro 5200:\n",
      "  âœ“ Descargado: 5200.txt\n",
      "[10/100] Libro 345:\n",
      "  âœ“ Descargado: 345.txt\n",
      "[11/100] Libro 43:\n",
      "  âœ“ Descargado: 43.txt\n",
      "[12/100] Libro 1080:\n",
      "  âœ“ Descargado: 1080.txt\n",
      "[13/100] Libro 76:\n",
      "  âœ“ Descargado: 76.txt\n",
      "[14/100] Libro 1260:\n",
      "  âœ“ Descargado: 1260.txt\n",
      "[15/100] Libro 46:\n",
      "  âœ“ Descargado: 46.txt\n",
      "[16/100] Libro 2542:\n",
      "  âœ“ Descargado: 2542.txt\n",
      "[17/100] Libro 74:\n",
      "  âœ“ Descargado: 74.txt\n",
      "[18/100] Libro 1497:\n",
      "  âœ“ Descargado: 1497.txt\n",
      "[19/100] Libro 16:\n",
      "  âœ“ Descargado: 16.txt\n",
      "[20/100] Libro 219:\n",
      "  âœ“ Descargado: 219.txt\n",
      "[21/100] Libro 1232:\n",
      "  âœ“ Descargado: 1232.txt\n",
      "[22/100] Libro 100:\n",
      "  âœ“ Descargado: 100.txt\n",
      "[23/100] Libro 1399:\n",
      "  âœ“ Descargado: 1399.txt\n",
      "[24/100] Libro 2600:\n",
      "  âœ“ Descargado: 2600.txt\n",
      "[25/100] Libro 209:\n",
      "  âœ“ Descargado: 209.txt\n",
      "[26/100] Libro 1184:\n",
      "  âœ“ Descargado: 1184.txt\n",
      "[27/100] Libro 205:\n",
      "  âœ“ Descargado: 205.txt\n",
      "[28/100] Libro 844:\n",
      "  âœ“ Descargado: 844.txt\n",
      "[29/100] Libro 1322:\n",
      "  âœ“ Descargado: 1322.txt\n",
      "[30/100] Libro 36:\n",
      "  âœ“ Descargado: 36.txt\n",
      "[31/100] Libro 2591:\n",
      "  âœ“ Descargado: 2591.txt\n",
      "[32/100] Libro 1400:\n",
      "  âœ“ Descargado: 1400.txt\n",
      "[33/100] Libro 2554:\n",
      "  âœ“ Descargado: 2554.txt\n",
      "[34/100] Libro 4300:\n",
      "  âœ“ Descargado: 4300.txt\n",
      "[35/100] Libro 158:\n",
      "  âœ“ Descargado: 158.txt\n",
      "[36/100] Libro 1250:\n",
      "  âœ“ Descargado: 1250.txt\n",
      "[37/100] Libro 244:\n",
      "  âœ“ Descargado: 244.txt\n",
      "[38/100] Libro 1998:\n",
      "  âœ“ Descargado: 1998.txt\n",
      "[39/100] Libro 730:\n",
      "  âœ“ Descargado: 730.txt\n",
      "[40/100] Libro 1727:\n",
      "  âœ“ Descargado: 1727.txt\n",
      "[41/100] Libro 768:\n",
      "  âœ“ Descargado: 768.txt\n",
      "[42/100] Libro 2814:\n",
      "  âœ“ Descargado: 2814.txt\n",
      "[43/100] Libro 161:\n",
      "  âœ“ Descargado: 161.txt\n",
      "[44/100] Libro 41:\n",
      "  âœ“ Descargado: 41.txt\n",
      "[45/100] Libro 1259:\n",
      "  âœ“ Descargado: 1259.txt\n",
      "[46/100] Libro 58:\n",
      "  âœ“ Descargado: 58.txt\n",
      "[47/100] Libro 996:\n",
      "  âœ“ Descargado: 996.txt\n",
      "[48/100] Libro 5740:\n",
      "  âœ— Error descargando 5740: No se pudo acceder\n",
      "[49/100] Libro 514:\n",
      "  âœ“ Descargado: 514.txt\n",
      "[50/100] Libro 2148:\n",
      "  âœ“ Descargado: 2148.txt\n",
      "[51/100] Libro 1251:\n",
      "  âœ“ Descargado: 1251.txt\n",
      "[52/100] Libro 3296:\n",
      "  âœ“ Descargado: 3296.txt\n",
      "[53/100] Libro 120:\n",
      "  âœ“ Descargado: 120.txt\n",
      "[54/100] Libro 45:\n",
      "  âœ“ Descargado: 45.txt\n",
      "[55/100] Libro 23:\n",
      "  âœ“ Descargado: 23.txt\n",
      "[56/100] Libro 37106:\n",
      "  âœ“ Descargado: 37106.txt\n",
      "[57/100] Libro 1112:\n",
      "  âœ“ Descargado: 1112.txt\n",
      "[58/100] Libro 3825:\n",
      "  âœ“ Descargado: 3825.txt\n",
      "[59/100] Libro 2000:\n",
      "  âœ“ Descargado: 2000.txt\n",
      "[60/100] Libro 1404:\n",
      "  âœ“ Descargado: 1404.txt\n",
      "[61/100] Libro 135:\n",
      "  âœ“ Descargado: 135.txt\n",
      "[62/100] Libro 105:\n",
      "  âœ“ Descargado: 105.txt\n",
      "[63/100] Libro 375:\n",
      "  âœ“ Descargado: 375.txt\n",
      "[64/100] Libro 64317:\n",
      "  âœ“ Descargado: 64317.txt\n",
      "[65/100] Libro 6130:\n",
      "  âœ“ Descargado: 6130.txt\n",
      "[66/100] Libro 19033:\n",
      "  âœ“ Descargado: 19033.txt\n",
      "[67/100] Libro 25344:\n",
      "  âœ“ Descargado: 25344.txt\n",
      "[68/100] Libro 28054:\n",
      "  âœ“ Descargado: 28054.txt\n",
      "[69/100] Libro 215:\n",
      "  âœ“ Descargado: 215.txt\n",
      "[70/100] Libro 4363:\n",
      "  âœ“ Descargado: 4363.txt\n",
      "[71/100] Libro 1998:\n",
      "  âœ“ 1998.txt ya existe\n",
      "[72/100] Libro 7849:\n",
      "  âœ“ Descargado: 7849.txt\n",
      "[73/100] Libro 8492:\n",
      "  âœ“ Descargado: 8492.txt\n",
      "[74/100] Libro 3207:\n",
      "  âœ“ Descargado: 3207.txt\n",
      "[75/100] Libro 30254:\n",
      "  âœ“ Descargado: 30254.txt\n",
      "[76/100] Libro 2500:\n",
      "  âœ“ Descargado: 2500.txt\n",
      "[77/100] Libro 160:\n",
      "  âœ“ Descargado: 160.txt\n",
      "[78/100] Libro 2265:\n",
      "  âœ“ Descargado: 2265.txt\n",
      "[79/100] Libro 829:\n",
      "  âœ“ Descargado: 829.txt\n",
      "[80/100] Libro 103:\n",
      "  âœ“ Descargado: 103.txt\n",
      "[81/100] Libro 4085:\n",
      "  âœ“ Descargado: 4085.txt\n",
      "[82/100] Libro 132:\n",
      "  âœ“ Descargado: 132.txt\n",
      "[83/100] Libro 1695:\n",
      "  âœ“ Descargado: 1695.txt\n",
      "[84/100] Libro 203:\n",
      "  âœ“ Descargado: 203.txt\n",
      "[85/100] Libro 113:\n",
      "  âœ“ Descargado: 113.txt\n",
      "[86/100] Libro 17135:\n",
      "  âœ“ Descargado: 17135.txt\n",
      "[87/100] Libro 408:\n",
      "  âœ“ Descargado: 408.txt\n",
      "[88/100] Libro 1400:\n",
      "  âœ“ 1400.txt ya existe\n",
      "[89/100] Libro 1155:\n",
      "  âœ“ Descargado: 1155.txt\n",
      "[90/100] Libro 2852:\n",
      "  âœ“ Descargado: 2852.txt\n",
      "[91/100] Libro 3600:\n",
      "  âœ“ Descargado: 3600.txt\n",
      "[92/100] Libro 599:\n",
      "  âœ“ Descargado: 599.txt\n",
      "[93/100] Libro 55:\n",
      "  âœ“ Descargado: 55.txt\n",
      "[94/100] Libro 14838:\n",
      "  âœ“ Descargado: 14838.txt\n",
      "[95/100] Libro 61:\n",
      "  âœ“ Descargado: 61.txt\n",
      "[96/100] Libro 2097:\n",
      "  âœ“ Descargado: 2097.txt\n",
      "[97/100] Libro 15399:\n",
      "  âœ“ Descargado: 15399.txt\n",
      "[98/100] Libro 67979:\n",
      "  âœ“ Descargado: 67979.txt\n",
      "[99/100] Libro 1257:\n",
      "  âœ“ Descargado: 1257.txt\n",
      "[100/100] Libro 15695:\n",
      "  âœ“ Descargado: 15695.txt\n",
      "\n",
      "============================================================\n",
      "âœ… Descarga completada:\n",
      "   Exitosos: 99\n",
      "   Fallidos: 1\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!python ../src/download_books.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbb3a574-0265-4750-89aa-423504f13b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/arturo/project_gutenberg/notebooks'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c157fae2-b3bd-4a3d-867c-08a0ef1d7f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
